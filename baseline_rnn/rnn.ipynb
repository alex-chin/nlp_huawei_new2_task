{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "\n",
    "from dataset import *\n",
    "from model import *\n",
    "from trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>target</th>\n",
       "      <th>movie_description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Furies</td>\n",
       "      <td>0</td>\n",
       "      <td>Three furious vigilantes unite to take down a ...</td>\n",
       "      <td>133529636342330622371894152500993949030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RRR</td>\n",
       "      <td>0</td>\n",
       "      <td>The story of freedom fighters Komaram Bheem an...</td>\n",
       "      <td>133529660110779376651195430564179049830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Wick</td>\n",
       "      <td>0</td>\n",
       "      <td>Legendary assassin John Wick (Keanu Reeves) re...</td>\n",
       "      <td>133529680710101630359923204885606137190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Wick: Chapter 3 -- Parabellum</td>\n",
       "      <td>0</td>\n",
       "      <td>After gunning down a member of the High Table ...</td>\n",
       "      <td>133529687048354631501070212369122164070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>0</td>\n",
       "      <td>After more than thirty years of service as one...</td>\n",
       "      <td>133529699724860633783364227336154217830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           movie_name  target  \\\n",
       "0                              Furies       0   \n",
       "1                                 RRR       0   \n",
       "2                           John Wick       0   \n",
       "3  John Wick: Chapter 3 -- Parabellum       0   \n",
       "4                   Top Gun: Maverick       0   \n",
       "\n",
       "                                   movie_description  \\\n",
       "0  Three furious vigilantes unite to take down a ...   \n",
       "1  The story of freedom fighters Komaram Bheem an...   \n",
       "2  Legendary assassin John Wick (Keanu Reeves) re...   \n",
       "3  After gunning down a member of the High Table ...   \n",
       "4  After more than thirty years of service as one...   \n",
       "\n",
       "                                        id  \n",
       "0  133529636342330622371894152500993949030  \n",
       "1  133529660110779376651195430564179049830  \n",
       "2  133529680710101630359923204885606137190  \n",
       "3  133529687048354631501070212369122164070  \n",
       "4  133529699724860633783364227336154217830  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../\"\n",
    "train = pd.read_csv(os.path.join(path, \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(path, \"test.csv\"))\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pretrained tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer()\n",
    "tok_texts = [tok.tokenize(t) for t in train.movie_description.values]\n",
    "vocab = Vocab(tok_texts, max_vocab_size=30000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels, val_texts, val_labels = train_test_split(train)\n",
    "train_dataset = TextDataset([tok.tokenize(t)\n",
    "                            for t in train_texts], train_labels, vocab)\n",
    "val_dataset = TextDataset([tok.tokenize(t)\n",
    "                          for t in val_texts], val_labels, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddings from tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to read local cache '/Users/20793788/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/nlp_huawei_new2_task/venv/lib/python3.10/site-packages/gensim/downloader.py:219\u001b[0m, in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# We need io.open here because Py2 open doesn't support encoding keyword\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39;49mopen(cache_path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m fin:\n\u001b[1;32m    220\u001b[0m         \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mload(fin)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/20793788/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# os.environ[\"GENSIM_DATA_DIR\"] = str(Path.cwd())\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gensim_model \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mglove-wiki-gigaword-100\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m emb_matrix \u001b[39m=\u001b[39m prepare_emb_matrix(gensim_model, vocab)\n",
      "File \u001b[0;32m~/Desktop/nlp_huawei_new2_task/venv/lib/python3.10/site-packages/gensim/downloader.py:490\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Download (if needed) dataset/model and load it to memory (unless `return_path` is set).\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \n\u001b[1;32m    488\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m _create_base_dir()\n\u001b[0;32m--> 490\u001b[0m file_name \u001b[39m=\u001b[39m _get_filename(name)\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncorrect model/corpus name\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/nlp_huawei_new2_task/venv/lib/python3.10/site-packages/gensim/downloader.py:426\u001b[0m, in \u001b[0;36m_get_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_filename\u001b[39m(name):\n\u001b[1;32m    413\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Retrieve the filename of the dataset/model.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m     information \u001b[39m=\u001b[39m info()\n\u001b[1;32m    427\u001b[0m     corpora \u001b[39m=\u001b[39m information[\u001b[39m'\u001b[39m\u001b[39mcorpora\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    428\u001b[0m     models \u001b[39m=\u001b[39m information[\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/nlp_huawei_new2_task/venv/lib/python3.10/site-packages/gensim/downloader.py:268\u001b[0m, in \u001b[0;36minfo\u001b[0;34m(name, show_only_latest, name_only)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfo\u001b[39m(name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, show_only_latest\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    229\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Provide the information related to model/dataset.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     information \u001b[39m=\u001b[39m _load_info()\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         corpora \u001b[39m=\u001b[39m information[\u001b[39m'\u001b[39m\u001b[39mcorpora\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/nlp_huawei_new2_task/venv/lib/python3.10/site-packages/gensim/downloader.py:222\u001b[0m, in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mload(fin)\n\u001b[1;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[39m'\u001b[39m\u001b[39munable to read local cache \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m during fallback, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mconnect to the Internet and retry\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m cache_path\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: unable to read local cache '/Users/20793788/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "os.environ[\"GENSIM_DATA_DIR\"] = str(Path.cwd())\n",
    "gensim_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "emb_matrix = prepare_emb_matrix(gensim_model, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Model and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"freeze\": False,\n",
    "    \"cell_type\": \"LSTM\",\n",
    "    \"cell_dropout\": 0.2,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 128,\n",
    "    \"out_activation\": \"relu\",\n",
    "    \"bidirectional\": True,\n",
    "    \"out_dropout\": 0.2,\n",
    "    \"out_sizes\": [200],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 3e-3,\n",
    "    \"n_epochs\": 10,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": 128,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcd356f1c2b45ada3e797e6c4265e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a001f8c9d242fd912de20e668b31d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9b068d82d24601839370e92d4e3ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1c92f83242488a8980921e5b07d0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48ee1e0c3fe42e288d2002382933c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64657f7bd4cb44d0b11db6f8499478ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa36c8ca6ad4c3eb62e1860cbbbdf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94370abbdbf3415693364913db13bf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d20353d726247f78f9ad0dc65d42759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac274f9618d4a648f41309ba1f91adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24790dc7e1524f6c9d4c4e217e28699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1be44f23c334b708e0d193d10ddd79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0b9385f94a4fa79c8cb0f0399b5164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec62d9396bef4556abeb1394810a356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a63b4507784ab2bed37b9c0afca235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b078aa1b191c4378b473ed2a8c44fb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9598fcddb2bd45b89c5b6285ce3e143d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23028b03093464b808bf371fddc3c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eedaf334b9642d7b765cdd341b7c966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9baf472688d46e8862cb37a3a98bdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RecurrentClassifier(\n",
       "  (embeddings): Embedding(30003, 100, padding_idx=0)\n",
       "  (cell): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (out_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (out_proj): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=200, bias=True)\n",
       "    (1): Linear(in_features=200, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=trainer_config[\"batch_size\"],\n",
    "                              shuffle=True,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=0,\n",
    "                            collate_fn=val_dataset.collate_fn)\n",
    "t = Trainer(trainer_config)\n",
    "t.fit(clf_model, train_dataloader, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(\"baseline_model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainer.load(\"baseline_model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    tok_text = tok.tokenize(text)\n",
    "    indexed_text = torch.tensor(vocab.vectorize(tok_text)).to(t.device)\n",
    "    genre = model(pack_sequence([indexed_text])).argmax().item()\n",
    "    return genre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get testset predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(TextDataset([tok.tokenize(t) for t in test.movie_description.values], [-1] * test.shape[0], vocab),\n",
    "                             batch_size=trainer_config[\"batch_size\"],\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "predictions = t.predict(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d996f823</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1cf01f9c</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856ea05c</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c97899ee</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73f0740f</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0  d996f823  Horror\n",
       "1  1cf01f9c   Drama\n",
       "2  856ea05c  Horror\n",
       "3  c97899ee  Horror\n",
       "4  73f0740f  Comedy"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\n",
    "sample_submission[\"target\"] = predictions\n",
    "sample_submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ce47e61e2a197e18f6178d2b52c72741babf3e522a6ab2c8e52c7be76b98a41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
